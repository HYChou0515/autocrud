# üöÄ AutoCRUD User Guide

AutoCRUD is an automated CRUD generator designed for FastAPI. It does more than just generate routes‚Äîit also provides versioning, soft delete, data migration, and flexible support for multiple storage backends.

## üì¶ Quick Start

With just a few lines of code, you can create a complete RESTful API for your data model.

```python
from fastapi import FastAPI
from autocrud import AutoCRUD
import msgspec

# 1. Define your data model (supports msgspec.Struct, dataclasses, etc.)
class User(msgspec.Struct):
    name: str
    email: str
    age: int

# 2. Initialize FastAPI and AutoCRUD
app = FastAPI()
autocrud = AutoCRUD()

# 3. Register the model
autocrud.add_model(User)

# 4. Apply the generated routes to FastAPI
autocrud.apply(app)

# 5. OpenAPI Integration
autocrud.openapi(app)
```

After starting the server, you will get the full set of CRUD endpoints under `/users`.

---

## ‚öôÔ∏è Initialization Settings (AutoCRUD)

When instantiating `AutoCRUD`, you can configure global behavior.

!!! seealso "API Reference"
    - [`autocrud.crud.core.AutoCRUD`](../reference/crud/core.md#autocrud.crud.core.AutoCRUD)

### Automatic Resource Naming (`model_naming`)

The `model_naming` parameter controls how resource names (Resource Name) are automatically generated from Python class names.

In AutoCRUD, resource names must be unique and are used directly as the URL path of the CRUD API (e.g., `/users`). Since Python classes typically use PascalCase (e.g., `UserProfile`), but this format is usually discouraged in URLs, you can use this parameter to define an automatic conversion rule‚Äîso you don‚Äôt need to manually specify `name` every time you call `add_model`.

The default value is `kebab` (kebab-case).

In addition to the built-in string options, you can also pass a function to implement custom naming logic.

```python hl_lines="3"
# Options: "same", "pascal", "camel", "snake", "kebab"
# Automatically convert UserProfile to user_profile
autocrud = AutoCRUD(model_naming="snake") 
autocrud_custom.add_model(UserProfile)
# Generated route: /user_profile
```

```python hl_lines="2-5"
# Or use a custom function
def my_naming(model_type: type) -> str:
    return f"api_{model_type.__name__.lower()}"

autocrud_custom = AutoCRUD(model_naming=my_naming)
autocrud_custom.add_model(UserProfile)
# Generated route: /api_userprofile
```

### Selecting a Storage Mode (`storage_factory`)

By default, AutoCRUD uses **Memory Storage**, which is suitable for rapid prototyping and testing. If you need data persistence, you can switch the storage backend via the `storage_factory` parameter.

```python hl_lines="7"
from autocrud import AutoCRUD, DiskStorageFactory
from pathlib import Path

# Switch to local Disk Storage
# Data will be stored in the ./data directory
autocrud = AutoCRUD(
    storage_factory=DiskStorageFactory(rootdir=Path("./data"))
)
```

!!! seealso "AutoCRUD supports multiple storage backends (Memory, Disk, Redis, S3, SQLite, PostgreSQL, etc.) as well as hybrid modes. For how to configure advanced storage backends or implement a custom Factory, see the [Storage](#storage) section below."

### Data Encoding (`encoding`)

The `encoding` parameter determines the serialization format used when storing data.

- `Encoding.json` (default): Uses JSON format, highly readable and suitable for debugging.
- `Encoding.msgpack`: Uses MessagePack format, smaller and faster, suitable for production.

```python hl_lines="5"
from autocrud import AutoCRUD
from autocrud.resource_manager.basic import Encoding

# Use MessagePack for efficient storage
autocrud = AutoCRUD(encoding=Encoding.msgpack)
```

### Default User and Time (`default_user` & `default_now`)

When the API request does not provide user information or a timestamp, AutoCRUD uses these default values to populate `created_by`, `updated_by`, `created_time`, and `updated_time`.

This is very convenient in test environments or single-user applications, as it eliminates the need to handle authentication and time injection.

```python hl_lines="5-6"
from datetime import datetime

# Set a fixed default user and a dynamic time provider
autocrud = AutoCRUD(
    default_user="system_admin",
    default_now=datetime.now
)
```

If these defaults are not set, then when operating `resource_manager` directly, you must explicitly provide user and time information via the `meta_provide` context manager‚Äîotherwise an error will be raised.

```python hl_lines="5"
# If default_user and default_now are not set
manager = autocrud.get_resource_manager(User)

# You must use meta_provide
with manager.meta_provide(user="current_user", now=datetime.now()):
    manager.create(User(name="Alice", email="alice@example.com", age=30))
```

### Dependency Injection (`dependency_provider`)

`dependency_provider` allows you to inject FastAPI `Depends` into the routes generated by AutoCRUD. This is useful for global validation (such as API key checks), database connection injection, or other pre-processing.

You need to implement the `DependencyProvider` class (or a subclass) and override the corresponding methods.

```python hl_lines="14"
from fastapi import Depends, HTTPException
from autocrud import AutoCRUD
from autocrud.crud.route_templates.basic import DependencyProvider

def verify_api_key(key: str):
    if key != "secret":
        raise HTTPException(403)

class MyDependency(DependencyProvider):
    # Inject dependencies into all routes
    def get_all_dependencies(self):
        return [Depends(verify_api_key)]

autocrud = AutoCRUD(dependency_provider=MyDependency())
```

### Event Handling (`event_handlers`)

AutoCRUD supports an event-driven architecture. You can register `IEventHandler` to listen to resource change events (such as `ResourceCreated`, `ResourceUpdated`, `ResourceDeleted`) and execute corresponding logic (such as sending notifications or triggering other services).

```python hl_lines="4-9"
from autocrud import AutoCRUD
from autocrud.types import IEventHandler, ResourceCreated

class NotificationHandler(IEventHandler):
    async def handle(self, event):
        if isinstance(event, ResourceCreated):
            print(f"New resource created: {event.resource_id}")

autocrud = AutoCRUD(event_handlers=[NotificationHandler()])
```

### Route Templates (`route_templates`)

By default, AutoCRUD generates a standard set of CRUD routes for each model (including Create, List, Read, Update, Patch, Delete, Restore, Switch Revision, etc.). If you want to customize the generated route set‚Äîfor example, generating a read-only API only, or adding custom route templates‚Äîyou can configure it via the `route_templates` parameter.

The default route template list includes:

- `CreateRouteTemplate`: Create a resource (POST)
- `ListRouteTemplate`: List query (GET)
- `ReadRouteTemplate`: Read a single resource (GET)
- `UpdateRouteTemplate`: Full update (PUT)
- `PatchRouteTemplate`: Partial update (PATCH)
- `DeleteRouteTemplate`: Soft delete (DELETE)
- `RestoreRouteTemplate`: Restore deleted resource (POST)
- `SwitchRevisionRouteTemplate`: Switch revision (POST)

You can pass a custom list to override the default behavior.

```python hl_lines="6-10"
from autocrud import AutoCRUD
from autocrud.crud.route_templates.get import ReadRouteTemplate
from autocrud.crud.route_templates.search import ListRouteTemplate

# Generate only read-related routes (Read-Only API)
autocrud = AutoCRUD(
    route_templates=[
        ListRouteTemplate(),
        ReadRouteTemplate()
    ]
)
```

In addition, you can dynamically add templates after initialization using the `add_route_template` method.

```python hl_lines="2"
# Add a custom search template
autocrud.add_route_template(MyCustomSearchTemplate())
```

!!! seealso "For the full route list, see [Auto-generated Routes](#auto-fastapi-routes)"

#### Implementing a Custom Template

To create your own route template, you can either inherit from `BaseRouteTemplate` (recommended) or implement the `IRouteTemplate` interface directly.

**Option 1: Inherit from BaseRouteTemplate (recommended)**

`BaseRouteTemplate` already handles `dependency_provider` injection and template ordering (`order`). You only need to focus on implementing the `apply` method to define routes.

```python
from fastapi import APIRouter
from autocrud.crud.route_templates.basic import BaseRouteTemplate

class MyCustomTemplate(BaseRouteTemplate):
    def apply(self, model_name, resource_manager, router: APIRouter):
        # Define your routes
        @router.get(f"/{model_name}/hello")
        async def hello():
            return {"message": f"Hello from {model_name}"}

autocrud.add_route_template(MyCustomTemplate())
```

**Option 2: Implement IRouteTemplate**

If you need full control over template behavior, you can implement the `IRouteTemplate` interface directly. You must implement the `apply` method and the `order` property yourself.

```python
from autocrud.crud.route_templates.basic import IRouteTemplate

class MyRawTemplate(IRouteTemplate):
    @property
    def order(self) -> int:
        return 999  # Smaller numbers run earlier

    def apply(self, model_name, resource_manager, router):
        # Implement routing logic
        pass
```

## üõ†Ô∏è Adding Models

When you register a resource with the `add_model` method, in addition to the base model class, AutoCRUD supports a variety of parameters for fine-grained, per-model customization. These settings override global configuration (if any).

!!! seealso "API Reference"
    - [`autocrud.crud.core.AutoCRUD.add_model`](../reference/crud/core.md#autocrud.crud.core.AutoCRUD.add_model)

### Custom Resource Name (`name`)

Specify the resource name used in the URL. If not set, it will be automatically generated according to the global `model_naming` rule.

```python hl_lines="2"
# The URL will become /people instead of /users
autocrud.add_model(User, name="people")
```

### Migration (`migration`)

When the model schema changes, implement the `IMigration` interface to handle upgrade logic for data from older versions. This is especially important for persistent storage (such as Disk, S3).

```python hl_lines="10"
from autocrud.types import IMigration

class UserMigration(IMigration):
    schema_version = "v2"
    
    def migrate(self, data, old_version):
        # Handle data upgrade
        return data

autocrud.add_model(User, migration=UserMigration())
```

!!! seealso "For the detailed mechanism and complete examples of Schema Migration, see the [Schema Migration](resource_manager.md#schema-migration) section."

### Indexed Fields (`indexed_fields`)

Specify which fields should be indexed to optimize query performance. You can provide field names or paths.

```python hl_lines="4"
# Create indexes for the email and age fields
autocrud.add_model(
    User, 
    indexed_fields=["email", "age"]
)
```

!!! seealso "For detailed explanations and query usage of indexed fields, see the [Data Attribute Index](resource_manager.md#data-attribute-index) section."

### Event Handlers (`event_handlers`)

AutoCRUD provides a powerful event-driven mechanism that allows you to inject custom logic at each stage of a resource operation (such as before create, after update, or on failure). This is especially useful for implementing audit logs, notification systems, data validation, or side-effect handling.

You can use the `event_handlers` parameter to register one or more event handlers for a specific model.

#### Using the Fluent API (Recommended)

AutoCRUD provides a convenient `do` function that lets you quickly register event handlers in a chained style, without defining extra classes.

```python hl_lines="1 8-12"
from autocrud.resource_manager.events import do
from autocrud.types import ResourceAction, EventContext

def log_creation(context: EventContext):
    print(f"User {context.user} is creating resource {context.resource_name}")

# Register event handlers
handlers = (
    do(log_creation).before(ResourceAction.create)
    .do(lambda ctx: print("Created successfully!"))
    .on_success(ResourceAction.create)
)

autocrud.add_model(User, event_handlers=handlers)
```

#### Implementing the `IEventHandler` Interface

For more complex logic, you can implement the `IEventHandler` interface. You need to implement `is_supported` to decide whether to handle the event, and `handle_event` to execute the actual logic.

```python
from autocrud.types import IEventHandler, EventContext, ResourceAction

class AuditLogHandler(IEventHandler):
    def is_supported(self, context: EventContext) -> bool:
        # Only handle write operations (Create, Update, Delete, etc.)
        return context.action in ResourceAction.write

    def handle_event(self, context: EventContext) -> None:
        # Log the operation
        print(f"[{context.phase}] {context.action.name} by {context.user}")

autocrud.add_model(User, event_handlers=[AuditLogHandler()])
```

#### Event Phases (Phases)

Each operation goes through the following phases:

- **before**: Before the operation runs. Useful for validating or modifying input data.
- **after**: After the operation runs (regardless of success or failure). Useful for cleanup.
- **on_success**: After the operation completes successfully. Useful for sending notifications.
- **on_failure**: When an error occurs. Useful for error logging.

#### Event Context (EventContext)

The `context` object passed to `handle_event` contains all information about the current operation:

- `action`: Current action type (ResourceAction.create, update, delete...)
- `phase`: Current phase (before, on_success...)
- `user`: Acting user
- `now`: Operation timestamp
- `resource_name`: Resource name
- `data`: (Create/Update only) Data being written
- `resource_id`: (Get/Update/Delete only) Target resource ID
- `info`: (on_success only) Resource metadata after completion

!!! seealso "For more detailed test examples of event handling, see `tests/test_event_handlers.py`."

### Data Encoding (`encoding`)

Specify the serialization format for a particular model, overriding the global setting.

```python hl_lines="3"
from autocrud.resource_manager.basic import Encoding

autocrud.add_model(User, encoding=Encoding.msgpack)
```

!!! seealso "For details on supported encoding formats, see the [Initialization Settings - Data Encoding](#encoding) section."

### Default Status (`default_status`)

Set the default revision status for newly created resources.

```python hl_lines="4"
from autocrud.types import RevisionStatus

# Newly created resources default to Draft
autocrud.add_model(User, default_status=RevisionStatus.draft)
```

### Default User & Time (`default_user` & `default_now`)

Set the default creator and time generator function for a specific model, with higher priority than the global setting.

```python hl_lines="3-4"
autocrud.add_model(
    User,
    default_user="system_bot",
    default_now=lambda: datetime.now(timezone.utc)
)
```

!!! seealso "For details on default user and time, see the [Initialization Settings - Default User & Time](#default-user-default-now) section."

### Custom ID Generator (`id_generator`)

By default, AutoCRUD uses UUID4 to generate resource IDs. You can pass a zero-argument function to customize the ID generation logic.

```python hl_lines="3-4 6"
import time

def timestamp_id():
    return f"user_{int(time.time())}"

autocrud.add_model(User, id_generator=timestamp_id)
```

---

## üíæ Backup & Restore

AutoCRUD includes a powerful built-in backup and restore mechanism, supporting exporting all data (including revision history) as a tar archive.

### Dump

```python
# Back up all data to a file
with open("backup.tar", "wb") as f:
    autocrud.dump(f)
```

### Load

```python
# Restore data from a backup file
# Note: You must register the same models first (add_model)
with open("backup.tar", "rb") as f:
    autocrud.load(f)
```

This is very useful for environment migration (for example, migrating from a development environment to production) or disaster recovery.

---

## Storage

AutoCRUD‚Äôs persistence layer uses a **Metadata** and **Payload** separation architecture, allowing the system to achieve both efficient query performance and large-scale data storage.

### Core Architecture

#### 1. Meta Store (Metadata Store)

Responsible for managing resource Metadata (such as ID, creation time, status, indexed fields, etc.). This layer primarily handles querying, sorting, pagination, and permission checks.

* **Characteristics**: Efficient queries, multi-field indexing.
* **Technology**: Typically RDBMS (PostgreSQL, SQLite) or Redis.
* **Use Cases**: Fast listing, resource filtering, permission validation.

#### 2. Resource Store (Resource Payload Store)

Responsible for storing the actual resource content (Payload) and its revision history. Each update generates a new version snapshot.

* **Characteristics**: Large-capacity storage, versioning, key-value access.
* **Technology**: Typically Object Storage (S3, MinIO) or the local file system.
* **Use Cases**: Store full data, file backups, revision rollback and restore.

### Design Rationale

By separating Metadata and Payload, AutoCRUD can flexibly combine different storage backends. For example, you can use Redis for ultra-fast list queries while using S3 to cheaply and securely store massive amounts of historical revision data.

When you perform CRUD operations, AutoCRUD automatically coordinates the two:

* **Create/Update**: The Meta Store records indexes and status; the Resource Store stores data snapshots.
* **List Queries**: Only access the Meta Store, making it extremely fast.
* **Read Detail**: First confirm permissions and location via the Meta Store, then fetch the data from the Resource Store.

### Technology Choices

You can inject different storage combinations via the `storage_factory` parameter. AutoCRUD provides multiple built-in factories and also supports custom implementations.

#### Built-in Factories

* **[MemoryStorageFactory](../reference/resource_manager/storage_factory.md#autocrud.resource_manager.storage_factory.MemoryStorageFactory)** (default): Fully in-memory storage, suitable for testing.
* **[DiskStorageFactory](../reference/resource_manager/storage_factory.md#autocrud.resource_manager.storage_factory.DiskStorageFactory)**: Local disk storage, suitable for single-machine persistence.

```python
from autocrud import AutoCRUD, DiskStorageFactory
from pathlib import Path

storage = DiskStorageFactory(rootdir=Path("./data"))
autocrud = AutoCRUD(storage_factory=storage)
```

!!! seealso "API Reference"
- [`autocrud.resource_manager.storage_factory.MemoryStorageFactory`](../reference/resource_manager/storage_factory.md#autocrud.resource_manager.storage_factory.MemoryStorageFactory)
- [`autocrud.resource_manager.storage_factory.DiskStorageFactory`](../reference/resource_manager/storage_factory.md#autocrud.resource_manager.storage_factory.DiskStorageFactory)

#### Custom Factory

To use an advanced Meta Store (such as Redis, SQLite) or a Resource Store (such as S3), you need to implement the `IStorageFactory` interface and return a `SimpleStorage` combination in the `build` method.

```python hl_lines="7-13"
from autocrud import IStorageFactory, AutoCRUD
from autocrud.resource_manager.core import SimpleStorage
# Import the stores you need
from autocrud.resource_manager.meta_store.redis import RedisMetaStore
from autocrud.resource_manager.resource_store.s3 import S3ResourceStore

class MyCustomStorageFactory(IStorageFactory):
    def build(self, model_name: str):
        # Combine the Meta Store and Resource Store you want here
        return SimpleStorage(
            meta_store=RedisMetaStore(redis_url="redis://localhost:6379"),
            resource_store=S3ResourceStore(bucket="my-bucket")
        )

autocrud = AutoCRUD(storage_factory=MyCustomStorageFactory())
```

!!! seealso "API Reference"
- [`autocrud.resource_manager.storage_factory.IStorageFactory`](../reference/resource_manager/storage_factory.md#autocrud.resource_manager.storage_factory.IStorageFactory)
- [`autocrud.resource_manager.core.SimpleStorage`](../reference/resource_manager/core.md#autocrud.resource_manager.core.SimpleStorage)

Below are detailed introductions and initialization examples for each type of Store. You can refer to these examples to implement your `build` method.
### Meta Store

The Meta Store is primarily responsible for resource indexing, querying, and status management.
Common technologies: PostgreSQL, SQLite, Redis
Supports: multi-field indexing, complex queries, pagination, sorting, permission auditing

!!! note
    Each Meta Store implements a unified interface (`IMetaStore`), allowing flexible replacement or combination based on your needs.

AutoCRUD currently supports the following Meta Store implementations:

#### **MemoryMetaStore**

- Implemented entirely with Python dict, data is stored in memory, and serialization uses msgspec.
- Suitable for testing, single-node caching, and temporary storage. Extremely fast but non-persistent.
- Supports basic CRUD, search, and sorting. Data is lost after restart.

```python
from autocrud.resource_manager.meta_store.simple import MemoryMetaStore

meta_store = MemoryMetaStore(encoding="msgpack")
```

!!! seealso "API Reference"
    - [`autocrud.resource_manager.meta_store.simple.MemoryMetaStore`](../reference/resource_manager/meta_store/simple.md#autocrud.resource_manager.meta_store.simple.MemoryMetaStore)

#### **DiskMetaStore**

- Each metadata entry is stored as an individual file in a specified directory, with serialization handled by msgspec.
- Suitable for small projects or local persistence. No database installation required, easy to back up and migrate.
- File names are based on `resource_id`, supports basic search and batch synchronization.

```python
from pathlib import Path
from autocrud.resource_manager.meta_store.simple import DiskMetaStore

meta_store = DiskMetaStore(
    rootdir=Path("./data/meta"), 
    encoding="msgpack"
)
```

!!! seealso "API Reference"
    - [`autocrud.resource_manager.meta_store.simple.DiskMetaStore`](../reference/resource_manager/meta_store/simple.md#autocrud.resource_manager.meta_store.simple.DiskMetaStore)

#### **SqliteMetaStore**

- Uses a SQLite database for storage. Metadata is stored in a BLOB column, with additional indexed fields (`indexed_data`).
- Supports SQL-level complex queries, sorting, and pagination. Suitable for single-node or embedded applications.
- Supports batch writes (`save_many`), persistent storage, and easy backup.

```python
from pathlib import Path
from autocrud.resource_manager.meta_store.sqlite3 import FileSqliteMetaStore

meta_store = FileSqliteMetaStore(
    db_filepath=Path("./data/meta.db"),
    encoding="msgpack"
)
```

!!! seealso "API Reference"
    - [`autocrud.resource_manager.meta_store.sqlite3.FileSqliteMetaStore`](../reference/resource_manager/meta_store/sqlite3.md#autocrud.resource_manager.meta_store.sqlite3.FileSqliteMetaStore)
    - [`autocrud.resource_manager.meta_store.sqlite3.MemorySqliteMetaStore`](../reference/resource_manager/meta_store/sqlite3.md#autocrud.resource_manager.meta_store.sqlite3.MemorySqliteMetaStore)

#### **PostgresMetaStore**

- Uses a PostgreSQL database for storage. Metadata is stored in a JSONB column, with GIN indexes for query optimization.
- Suitable for production environments, high concurrency, strong consistency, and complex query scenarios.
- Supports full SQL querying capabilities and transactional guarantees.

```python
from autocrud.resource_manager.meta_store.postgres import PostgresMetaStore

meta_store = PostgresMetaStore(
    pg_dsn="postgresql://user:password@localhost:5432/dbname",
    encoding="msgpack"
)
```

!!! seealso "API Reference"
    - [`autocrud.resource_manager.meta_store.postgres.PostgresMetaStore`](../reference/resource_manager/meta_store/postgres.md#autocrud.resource_manager.meta_store.postgres.PostgresMetaStore)

#### **RedisMetaStore**

- Uses Redis as the backend. All metadata is stored as key-value pairs, with serialization handled by msgspec.
- Suitable for high-concurrency and distributed caching scenarios. Supports batch synchronization (`get_then_delete`) and fast queries.
- Data persistence depends on Redis configuration. Suitable for temporary storage or synchronization to slower storage.

```python
from autocrud.resource_manager.meta_store.redis import RedisMetaStore

meta_store = RedisMetaStore(
    redis_url="redis://localhost:6379/0",
    encoding="msgpack",
    prefix="my_app"
)
```

!!! seealso "API Reference"
    - [`autocrud.resource_manager.meta_store.redis.RedisMetaStore`](../reference/resource_manager/meta_store/redis.md#autocrud.resource_manager.meta_store.redis.RedisMetaStore)

#### **FastSlowMetaStore**

- **Architecture**: A hybrid storage strategy combining a Fast Store (e.g., Redis) and a Slow Store (e.g., PostgreSQL).
- **Write Strategy**: Data is first written to the fast store and returned immediately, ensuring high-throughput write performance.
- **Synchronization Mechanism**: A built-in background thread periodically migrates data from the fast store to the slow store in **batches**. This leverages the fact that slow stores (e.g., RDBMS) are **much faster at batch writes than repeated single-row writes**, significantly improving persistence efficiency.
- **Read Strategy**: Reads are served from the fast store first, and fall back to the slow store on cache miss.
- **Search**: Executing a search automatically triggers synchronization to ensure the slow store's indexed data is up to date.
- **Use Cases**: Write-heavy applications that require durable persistence, such as log collection and real-time analytics.

```python
from autocrud.resource_manager.meta_store.fast_slow import FastSlowMetaStore
from autocrud.resource_manager.meta_store.redis import RedisMetaStore
from autocrud.resource_manager.meta_store.postgres import PostgresMetaStore

meta_store = FastSlowMetaStore(
    fast_store=RedisMetaStore(redis_url="redis://localhost:6379/0"),
    slow_store=PostgresMetaStore(pg_dsn="postgresql://user:password@localhost:5432/dbname"),
    sync_interval=1  # synchronize once per second
)
```

!!! seealso "API Reference"
    - [`autocrud.resource_manager.meta_store.fast_slow.FastSlowMetaStore`](../reference/resource_manager/meta_store/fast_slow.md#autocrud.resource_manager.meta_store.fast_slow.FastSlowMetaStore)
### Resource Store

Resource Store is responsible for storing the resource payload and managing versioning.
Common technologies: S3, Disk, local filesystem
Supports: multi-version data, rollback, restore, large file management

!!! note
    Each Resource Store implements a unified interface (`IResourceStore`), so you can flexibly swap or combine implementations based on your needs.
AutoCRUD currently supports the following Resource Store implementations:

#### **MemoryResourceStore**  
  - Implemented entirely with Python dict; all data and revisions are stored in memory.  
  - Suitable for testing, single-node caching, and temporary storage. Extremely fast, but not persistent.
  - Supports multiple revisions and instant rollback; data will be lost after restart.

  ```python
  from autocrud.resource_manager.resource_store.simple import MemoryResourceStore
  
  res_store = MemoryResourceStore(encoding="msgpack")
  ```
!!! seealso "API Reference"
        - [`autocrud.resource_manager.resource_store.simple.MemoryResourceStore`](../reference/resource_manager/resource_store/simple.md#autocrud.resource_manager.resource_store.simple.MemoryResourceStore)


#### **DiskResourceStore**  
  - Stores each resource revision as a separate file in a local directory, managing all revisions with a structured directory layout.  
  - Suitable for small projects and local persistence; easy to back up and migrate.
  - Supports multiple revisions, rollback, and restore. File names and directory structure are organized by resource_id/revision_id/schema_version.

  ```python
  from pathlib import Path
  from autocrud.resource_manager.resource_store.simple import DiskResourceStore
  
  res_store = DiskResourceStore(
      rootdir=Path("./data/resources"),
      encoding="msgpack"
  )
  ```
!!! seealso "API Reference"
    - [`autocrud.resource_manager.resource_store.simple.DiskResourceStore`](../reference/resource_manager/resource_store/simple.md#autocrud.resource_manager.resource_store.simple.DiskResourceStore)



#### **S3ResourceStore**  
  - Uses S3 or MinIO as the backend. All revision data and information are stored as S3 objects and indexed by UID.  
  - Suitable for cloud, large-scale data, and distributed storage; supports high availability and backups.
  - Supports multiple revisions, rollback, and restore. The index structure is designed for fast lookup of any revision.

  ```python
  from autocrud.resource_manager.resource_store.s3 import S3ResourceStore
  
  res_store = S3ResourceStore(
      endpoint_url="http://minio:9000",
      bucket="my-bucket",
      prefix="resources/",
      encoding="msgpack",
      access_key_id="minioadmin",
      secret_access_key="minioadmin"
  )
  ```
!!! seealso "API Reference"
    - [`autocrud.resource_manager.resource_store.s3.S3ResourceStore`](../reference/resource_manager/resource_store/s3.md#autocrud.resource_manager.resource_store.s3.S3ResourceStore)

#### **CachedS3ResourceStore**
!!! info "New in version 0.6.9"

  - **Architecture**: An enhanced version of `S3ResourceStore`, combining a local cache (e.g., Memory Cache).
  - **Read strategy**: Read from cache first; on cache miss, download from S3 and backfill the cache.
  - **Write strategy**: Dual-write to both cache and S3 to ensure consistency.
  - **TTL control**: Different TTLs are set based on resource status (draft: 60s, stable: 3600s).
  - **Performance benefits**: Significantly reduces S3 read latency and cost, especially suitable for read-heavy, write-light scenarios.

  **Read flow**:
  ```mermaid
  flowchart TD
    A[Read Request] --> B{Check Cache}
    B -->|Hit| C[Return Cached Data]
    B -->|Miss| D[Download from S3]
    D --> E[Write to Cache<br/>Set TTL]
    E --> F[Return Data]
  ```

  **Write flow**:
  ```mermaid
  flowchart TD
    A[Write Request] --> B[Write to Cache in parallel]
    A --> C[Write to S3 in parallel]
    B --> D[Done]
    C --> D
  ```

  ```python
  from autocrud.resource_manager.resource_store.cached_s3 import CachedS3ResourceStore
  from autocrud.resource_manager.resource_store.cache import MemoryCache

  res_store = CachedS3ResourceStore(
      caches=[MemoryCache()],
      ttl_draft=60,      # TTL for Draft status (seconds)
      ttl_stable=3600,   # TTL for Stable status (seconds)
      endpoint_url="http://minio:9000",
      bucket="my-bucket",
      prefix="resources/",
      access_key_id="minioadmin",
      secret_access_key="minioadmin"
  )
  ```
!!! seealso "API Reference"
    - [`autocrud.resource_manager.resource_store.cached_s3.CachedS3ResourceStore`](../reference/resource_manager/resource_store/cached_s3.md#autocrud.resource_manager.resource_store.cached_s3.CachedS3ResourceStore)

#### **ETagCachedS3ResourceStore**
!!! info "New in version 0.7.3"

  - **Architecture**: An advanced `CachedS3ResourceStore` that uses the HTTP ETag mechanism for cache validation.
  - **Validation strategy**: Before reading, issue a HEAD request to check S3's ETag; only re-download when changes are detected.
  - **Performance benefits**: HEAD requests are far cheaper than GET, greatly reducing unnecessary data transfer.
  - **Use cases**: Scenarios where data changes infrequently but freshness must be guaranteed.

  **ETag validation flow**:
  ```mermaid
  flowchart TD
    A[Read Request] --> B{Check Cache}
    B -->|Miss| G[Download from S3]
    B -->|Hit| C[HEAD Request<br/>Fetch S3 ETag]
    C --> D{Compare ETag}
    D -->|Same| E[Return Cached Data<br/>Save bandwidth]
    D -->|Different| F[Invalidate Cache]
    F --> G
    G --> H[Store Data + ETag]
    H --> I[Return Data]
  ```

  ```python
  from autocrud.resource_manager.resource_store.etag_cached_s3 import ETagCachedS3ResourceStore
  from autocrud.resource_manager.resource_store.cache import MemoryCache

  res_store = ETagCachedS3ResourceStore(
      caches=[MemoryCache()],
      ttl_draft=60,
      ttl_stable=3600,
      endpoint_url="http://minio:9000",
      bucket="my-bucket",
      prefix="resources/",
      access_key_id="minioadmin",
      secret_access_key="minioadmin"
  )
  ```
!!! seealso "API Reference"
    - [`autocrud.resource_manager.resource_store.etag_cached_s3.ETagCachedS3ResourceStore`](../reference/resource_manager/resource_store/etag_cached_s3.md#autocrud.resource_manager.resource_store.etag_cached_s3.ETagCachedS3ResourceStore)

#### **MQCachedS3ResourceStore**
!!! info "New in version 0.7.3"

  - **Architecture**: A `CachedS3ResourceStore` that uses RabbitMQ for cross-instance cache invalidation.
  - **Synchronization**: On writes, sends invalidation messages to RabbitMQ; all instances automatically clear their local caches upon receipt.
  - **Subscription model**: Built-in background thread subscribes to the invalidation queue and handles cache synchronization automatically.
  - **Performance benefits**: No need to check S3 on every read‚Äîhighest efficiency; suitable for multi-instance deployments.
  - **Use cases**: Distributed systems, multi-instance deployments, and scenarios requiring strong consistency.

  **Read flow**:
  ```mermaid
  flowchart TD
    A[Read Request] --> B{Check Cache}
    B -->|Hit| C[Return Cached Data]
    B -->|Miss| D[Download from S3]
    D --> E[Write to Cache]
    E --> F[Return Data]
  ```

  **Cross-instance synchronization flow**:
  ```mermaid
  flowchart TD
    subgraph Instance A
      A1[Write Resource] --> A2[Update S3]
      A2 --> A3[Send Invalidation<br/>to RabbitMQ]
      A3 --> A4[Update Local Cache]
    end
    
    subgraph RabbitMQ
      MQ[Invalidation Queue]
    end
    
    subgraph Instance B
      B1[Background Thread<br/>Subscribe Queue] --> B2[Receive Message]
      B2 --> B3[Invalidate<br/>Local Cache]
    end
    
    subgraph Instance C
      C1[Background Thread<br/>Subscribe Queue] --> C2[Receive Message]
      C2 --> C3[Invalidate<br/>Local Cache]
    end
    
    A3 -.->|Publish| MQ
    MQ -.->|Subscribe| B1
    MQ -.->|Subscribe| C1
    
    style A1 fill:#e1f5ff
    style B3 fill:#ffe1e1
    style C3 fill:#ffe1e1
  ```

  ```python
  from autocrud.resource_manager.resource_store.mq_cached_s3 import MQCachedS3ResourceStore
  from autocrud.resource_manager.resource_store.cache import MemoryCache

  res_store = MQCachedS3ResourceStore(
      caches=[MemoryCache()],
      amqp_url="amqp://guest:guest@localhost:5672/",
      queue_prefix="autocrud:",
      ttl_draft=60,
      ttl_stable=3600,
      endpoint_url="http://minio:9000",
      bucket="my-bucket",
      prefix="resources/",
      access_key_id="minioadmin",
      secret_access_key="minioadmin"
  )
  ```
!!! seealso "API Reference"
    - [`autocrud.resource_manager.resource_store.mq_cached_s3.MQCachedS3ResourceStore`](../reference/resource_manager/resource_store/mq_cached_s3.md#autocrud.resource_manager.resource_store.mq_cached_s3.MQCachedS3ResourceStore)
### üìä Performance Benchmark

--8<-- "docs/includes/benchmarks/resource_store.md"

--8<-- "docs/includes/benchmarks/metastore.md"


## üîí Advanced Features

### Permission Control

You can quickly set a super admin via the `admin` parameter, or implement `IPermissionChecker` for fine-grained permission control.

```python
# Enable RBAC and set the admin user
autocrud = AutoCRUD(admin="admin_user_id")
```

### Migration

When the Data Model schema changes (e.g., adding new fields), you can handle upgrades for legacy data by implementing the `IMigration` interface.

```python
class UserMigration(IMigration):
    schema_version = "v2"
    
    def migrate(self, data, old_version):
        # Handle data transformation logic
        if "new_field" not in data:
            data["new_field"] = "default_value"
        return data

autocrud.add_model(User, migration=UserMigration())
```

---

## üìë OpenAPI Integration

To ensure FastAPI‚Äôs auto-generated docs (Swagger UI / ReDoc) correctly display AutoCRUD‚Äôs dynamically generated models and `msgspec` structures, you need to explicitly call the `openapi` method.

### Basic Usage

Call `openapi(app)` after `apply(app)`:

```python hl_lines="6"
# ... register models ...

autocrud.apply(app)

# Inject OpenAPI Schema
autocrud.openapi(app)
```

This fixes the issue where FastAPI cannot recognize `msgspec.Struct` or dynamically generated classes by default, ensuring the API documentation is complete and accurate.

### Include Additional Models

If you have custom `msgspec` models that you want to appear in the API documentation, pass them via the `structs` parameter:

```python hl_lines="5"
class ErrorResponse(msgspec.Struct):
    error: str
    detail: str

autocrud.openapi(app, structs=[ErrorResponse])
```

---

## üö¶ Auto-Generated Route List

When you register a resource in AutoCRUD (e.g., TodoItem, User), the system automatically generates a set of RESTful API routes. These routes are based on the resource name you provide and automatically handle various operations for that resource.

### Route Format

* `[resource]` represents the registered resource name (e.g., todo-item, user)
* `{resource_id}` represents the unique identifier of the resource
* `{revision_id}` represents the revision identifier

### Routes

| Method | Path                                           | Description                                    |
| ------ | ---------------------------------------------- | ---------------------------------------------- |
| POST   | /[resource]                                    | Create a new [resource]                        |
| GET    | /[resource]/data                               | Get data for all [resource]                    |
| GET    | /[resource]/meta                               | Get metadata for all [resource]                |
| GET    | /[resource]/revision-info                      | Get current revision info for all [resource]   |
| GET    | /[resource]/full                               | Get full info for all [resource]               |
| GET    | /[resource]/count                              | Get the count of [resource]                    |
| GET    | /[resource]/{resource_id}/meta                 | Get metadata for a specific [resource]         |
| GET    | /[resource]/{resource_id}/revision-info        | Get revision info for a specific [resource]    |
| GET    | /[resource]/{resource_id}/full                 | Get full info for a specific [resource]        |
| GET    | /[resource]/{resource_id}/revision-list        | Get revision history for a specific [resource] |
| GET    | /[resource]/{resource_id}/data                 | Get data for a specific [resource]             |
| PUT    | /[resource]/{resource_id}                      | Update a specific [resource] (full update)     |
| PATCH  | /[resource]/{resource_id}                      | Partially update a specific [resource]         |
| DELETE | /[resource]/{resource_id}                      | Delete a specific [resource] (soft delete)     |
| POST   | /[resource]/{resource_id}/switch/{revision_id} | Switch to a specific revision                  |
| POST   | /[resource]/{resource_id}/restore              | Restore a specific [resource]                  |
| GET    | /blobs/{file_id}                               | Get Blob file content (Binary Data)            |

### List Search & Filtering

For list-style endpoints (e.g., `GET /[resource]/data`, `GET /[resource]/meta`, `GET /[resource]/count`), the following query parameters are supported for search and pagination:

* **`limit`**: (Query, int) Limit the number of returned items. Default is 10.
* **`offset`**: (Query, int) Pagination offset. Default is 0.
* **`qb`**: (Query, string) **Query Builder expression**, providing concise, type-safe query syntax (recommended).
* **`conditions`**: (Query, JSON String) **Generic filter conditions**, usable for filtering Metadata (e.g., created time) or Data fields.
* **`data_conditions`**: (Query, JSON String) **Data field filter conditions**, specifically for filtering Data fields.
* **`sorts`**: (Query, JSON String) Sort conditions.
* **`partial`**: (Query, list[string]) Fields to return (JSON Pointer format).

!!! note
    The `qb` parameter is mutually exclusive with `conditions`/`data_conditions`/`sorts`. Choose one. If provided together, the API will return a 422 error.

#### Method 1: Use QB Expressions (Recommended)

!!! info "New in version 0.7.5"


QB (Query Builder) provides Python-style query syntax, allowing you to build complex queries in an intuitive and type-safe way.

**Basic Syntax**:

```python
# Simple equality condition
QB['field'] == value

# Method usage
QB['field'].gt(value)      # Greater than
QB['field'].gte(value)     # Greater than or equal to
QB['field'].lt(value)      # Less than
QB['field'].lte(value)     # Less than or equal to
QB['field'].eq(value)      # Equal to
QB['field'].ne(value)      # Not equal to

# Logical composition
QB['age'].gt(18) & QB['status'].eq('active')    # AND
QB['age'].lt(18) | QB['age'].gt(65)             # OR
~QB['is_deleted'].eq(True)                       # NOT

# String operations
QB['name'].contains('John')                      # Contains
QB['email'].starts_with('admin')                 # Starts with
QB['filename'].ends_with('.pdf')                 # Ends with
QB['email'].icontains('ADMIN')                   # Case-insensitive contains

# List operations
QB['status'].in_(['active', 'pending'])          # In list
QB['role'].not_in(['guest', 'banned'])           # Not in list

# Range query
QB['age'].between(18, 65)                        # Between range

# Null checks
QB['optional_field'].is_null()                   # Is null
QB['required_field'].is_not_null()               # Is not null

# Boolean checks
QB['verified'].is_true()                         # Is true
QB['deleted'].is_false()                         # Is false
QB['field'].is_truthy()                          # Truthy check
QB['field'].is_falsy()                           # Falsy check

# Sorting & pagination
QB['age'].gt(18).sort('-created_time')           # Descending sort
QB['age'].gt(18).order_by('+name', '-age')       # Multi-field sort
QB['status'].eq('active').limit(20).offset(10)   # Pagination
QB['status'].eq('active').page(2, 20)            # Page 2, 20 items per page
QB['status'].eq('active').first()                # First item only

# Meta field queries
QB.resource_id().starts_with('user-')            # Resource ID
QB.created_time().today()                        # Created today
QB.created_time().this_week()                    # Created this week
QB.created_time().last_n_days(7)                 # Last 7 days
QB.updated_by().eq('admin')                      # Updated by

# Advanced composition
QB.all(                                          # Match all
    QB['age'].gt(18), 
    QB['status'].eq('active'),
    QB['verified'].eq(True)
)
QB.any(                                          # Match any
    QB['role'].eq('admin'),
    QB['role'].eq('moderator')
)
```

**URL Query Examples**Ôºö

!!! note
    For readability, the examples below show unencoded URLs. In actual usage, your HTTP client will handle URL encoding automatically.

```bash
# Basic query (unencoded, human-readable)
GET /user/data?qb=QB['department'].eq('Engineering')

# Complex conditions (unencoded, human-readable)
GET /user/data?qb=QB['age'].gt(18) & QB['status'].eq('active')
```

**Actual HTTP Request Examples**Ôºö

```bash
# Using curl (auto-encoding)
curl -G "http://localhost:8000/user/data" \
  --data-urlencode "qb=QB['age'].gt(18) & QB['status'].eq('active')"

# Actual URL (encoded)
# http://localhost:8000/user/data?qb=QB%5B%27age%27%5D.gt%2818%29%20%26%20QB%5B%27status%27%5D.eq%28%27active%27%29
```

```python
# Python requests (auto-encoding)
import requests

response = requests.get('http://localhost:8000/user/data', params={
    'qb': "QB['age'].gt(18) & QB['status'].eq('active')"
})

# JavaScript/axios (auto-encoding)
// axios.get('/user/data', {
//   params: { qb: "QB['age'].gt(18) & QB['status'].eq('active')" }
// })
```

**More QB Query Examples**Ôºö

```bash
# Sorting and pagination
GET /user/data?qb=QB['age'].gt(18).sort('-created_time').limit(20)

# Meta field query
GET /user/data?qb=QB.created_time().today() & QB['status'].eq('active')

# String search
GET /user/data?qb=QB['email'].contains('@example.com')

# List filtering
GET /user/data?qb=QB['status'].in_(['active', 'pending', 'approved'])
```

**Using in Python**Ôºö

```python
from autocrud.query import QB

# Build a query
query = (
    QB['age'].gt(18) 
    & QB['status'].eq('active')
    .sort('-created_time')
    .limit(20)
)

# Execute the query
result = manager.search(query.build())
```

**Supported operator shortcuts**Ôºö

```python
QB['age'] == 25        # Equivalent to QB['age'].eq(25)
QB['age'] != 25        # Equivalent to QB['age'].ne(25)
QB['age'] > 18         # Equivalent to QB['age'].gt(18)
QB['age'] >= 18        # Equivalent to QB['age'].gte(18)
QB['age'] < 65         # Equivalent to QB['age'].lt(65)
QB['age'] <= 65        # Equivalent to QB['age'].lte(65)
QB['status'] << ['a']  # Equivalent to QB['status'].in_(['a', 'b'])
QB['tags'] >> 'python' # Equivalent to QB['tags'].contains('python')
QB['code'] % r'^[A-Z]' # Equivalent to QB['code'].regex(r'^[A-Z]')
```

**Security**Ôºö

QB expressions use an AST (Abstract Syntax Tree) parser rather than `eval()`, ensuring safety:

- ‚úÖ Only methods and operators on an allowlist are permitted
- ‚úÖ Arbitrary function calls are forbidden
- ‚úÖ File I/O and system calls are forbidden
- ‚úÖ Supports the `datetime` module for time-based queries

**datetime support**Ôºö

```python
# Build time conditions with datetime
QB.created_time().gt(datetime.datetime(2024, 1, 1))
QB.created_time().between(
    datetime.datetime(2024, 1, 1), 
    datetime.datetime(2024, 12, 31)
)

# Relative time
QB.created_time().gt(datetime.datetime.now() - datetime.timedelta(days=7))
```

!!! seealso "For the complete Query Builder syntax, advanced usage, and examples, see [Query Builder Complete Guide](query_builder_guide.md)„ÄÇ"

#### Method 2: Filter using `conditions`

The `conditions` parameter accepts a URL-encoded JSON Array string that defines one or more filter conditions.
    
**Condition object structure**:

```json
{
  "field_path": "field name",   // Metadata field (e.g., created_time) or Data field
  "operator": "operator",       // Comparison operator
  "value": "value"              // Value to compare against
}
```

**Supported Metadata fields**:

- `resource_id`, `revision_id`
- `created_time`, `updated_time`
- `created_by`, `updated_by`
- `is_deleted`

**Supported operators**:

- `equals`, `not_equals`
- `greater_than`, `greater_than_or_equal`, `less_than`, `less_than_or_equal`
- `contains`, `starts_with`, `ends_with`
- `in_list`, `not_in_list`

**Example**: 
Query resources created after `2024` and whose `resource_id` starts with `usr-`:

```
?conditions=[{"field_path":"created_time","operator":"greater_than","value":"2024-01-01T00:00:00"},{"field_path":"resource_id","operator":"starts_with","value":"usr-"}]
```

### Usage Example

Assume the resource you registered is `todo-item`. The following routes will be auto-generated:

- `POST /todo-item` Create a new to-do item
- `GET /todo-item/{id}/data` Get the data of a specific to-do item
- `PATCH /todo-item/{id}` Partial update
- `DELETE /todo-item/{id}` Delete
- ...

You only need to provide the resource schema. AutoCRUD will automatically handle CRUD operations, versioning, restore, and more‚Äîmaking API development much simpler.

### Binary Data Download and Reading

!!! info "New in version 0.7.0"


If a resource includes fields of type `Binary` (e.g., images, documents), then on normal GET routes (e.g., GET `/[resource]/{id}/data`), to avoid transferring large and unnecessary data, the `data` attribute inside `Binary` fields is **UNSET** by default (i.e., it will not be included in the response). Only Metadata (such as `file_id`, `size`, `content_type`) is returned.

To retrieve the raw file content, use the `/blobs/{file_id}` route.

- **Path**: `GET /blobs/{file_id}`
- **Purpose**: Download the binary file.
- **Behavior**:
    1. **Redirect**: If the backend storage (e.g., S3) supports generating public or signed URLs, this endpoint returns `307 Temporary Redirect` and sends the client to that URL to download the file, reducing load on the API server.
    2. **Streaming**: If Redirect is not supported (e.g., Local Disk), it streams the file content directly (Stream Response).

**Response example (GET Resource)**:

```json
{
  "name": "My Document",
  "attachment": {
    "file_id": "blob-123456...",
    "content_type": "application/pdf",
    "size": 5242880
    // The "data" field is omitted (UNSET)
  }
}
```

**Download the file**:
Request `GET /blobs/blob-123456...` to obtain the original PDF file.

## ‚öõÔ∏è GraphQL

!!! info "New in version 0.6.8"


AutoCRUD supports auto-generating a GraphQL API, allowing you to flexibly query only the fields you need and avoid over-fetching.

### Enable GraphQL

To enable GraphQL support, register `GraphQLRouteTemplate`:

```python
from autocrud.crud.route_templates.graphql import GraphQLRouteTemplate

# Register the GraphQL template
crud.add_route_template(GraphQLRouteTemplate())
```

After enabling it, you can access the `/graphql` endpoint to use GraphQL Playground.

### Query Examples

Assume you have a `User` resource. AutoCRUD will automatically generate the following queries:

1. **Fetch a single resource (`user`)**
2. **Search a resource list (`user_list`)**

#### 1. Basic query and field selection (Partial Fetching)

Fetch only the fields you need (e.g., `name` and `email`). The system will automatically optimize backend queries.

```graphql
query {
  user(resource_id: "user_123") {
    data {
      name
      email
    }
    meta {
      created_time
      updated_time
    }
  }
}
```

#### 2. List search and filtering

Supports various filtering conditions and sorting.

```graphql
query {
  user_list(
    query: {
      limit: 10,
      offset: 0,
      # Filter by data fields
      data_conditions: [
        { field_path: "age", operator: greater_than, value: 18 },
        { field_path: "role", operator: equals, value: "admin" }
      ],
      # Sorting
      sorts: [
        { type: meta, key: created_time, direction: descending }
      ]
    }
  ) {
    data {
      name
      age
    }
  }
}
```

### Supported Features

- **Partial Fetching**: Reads only the requested fields from the backend, significantly improving performance.
- **Filtering**: Supports operators such as `eq`, `ne`, `gt`, `gte`, `lt`, `lte`, `contains`, `in`, `not_in`, etc.
- **Sorting**: Supports sorting by Meta fields (e.g., created time) or Data fields.
- **Pagination**: Supports pagination via `limit` and `offset`.
- **Revision Control**: You can specify `revision_id` to query a specific historical revision.

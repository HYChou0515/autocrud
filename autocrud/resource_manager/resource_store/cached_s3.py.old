from collections.abc import Generator
from contextlib import contextmanager
from typing import IO
import io

from autocrud.resource_manager.resource_store.s3 import S3ResourceStore
from autocrud.resource_manager.resource_store.cache import ICache
from autocrud.types import RevisionInfo


class CachedS3ResourceStore(S3ResourceStore):
    def __init__(
        self,
        caches: list[ICache] | None = None,
        **kwargs,
    ):
        super().__init__(**kwargs)
        self.caches = caches or []

    def get_revision_info(
        self, resource_id: str, revision_id: str, schema_version: str | None
    ) -> RevisionInfo:
        # Check caches
        for cache in self.caches:
            info = cache.get_revision_info(resource_id, revision_id, schema_version)
            if info:
                return info

        # Cache miss
        info = super().get_revision_info(resource_id, revision_id, schema_version)

        # Populate caches
        for cache in self.caches:
            cache.put_revision_info(info)

        return info

    @contextmanager
    def get_data_bytes(
        self, resource_id: str, revision_id: str, schema_version: str | None
    ) -> Generator[IO[bytes], None, None]:
        # Check caches
        for cache in self.caches:
            stream = cache.get_data(resource_id, revision_id, schema_version)
            if stream:
                try:
                    yield stream
                finally:
                    stream.close()
                return

        # Cache miss
        with super().get_data_bytes(resource_id, revision_id, schema_version) as stream:
            data = stream.read()

            # Populate caches
            for cache in self.caches:
                cache.put_data(resource_id, revision_id, schema_version, data)

            yield io.BytesIO(data)

    def save(self, info: RevisionInfo, data: IO[bytes]) -> None:
        # We need to read data to save to S3 AND cache.
        # But stream can be read only once.
        # So we read to memory first.
        content = data.read()

        # Save to S3 using BytesIO
        super().save(info, io.BytesIO(content))

        # Save to caches
        for cache in self.caches:
            cache.put_revision_info(info)
            cache.put_data(
                info.resource_id, info.revision_id, info.schema_version, content
            )
